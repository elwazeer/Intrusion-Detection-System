{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../kyoto/kyoto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Service</th>\n",
       "      <th>Source_bytes</th>\n",
       "      <th>Destination_bytes</th>\n",
       "      <th>Count</th>\n",
       "      <th>Same_srv_rate</th>\n",
       "      <th>Serror_rate</th>\n",
       "      <th>Srv_serror_rate</th>\n",
       "      <th>Dst_host_count</th>\n",
       "      <th>Dst_host_srv_count</th>\n",
       "      <th>Dst_host_same_src_port_rate</th>\n",
       "      <th>Dst_host_serror_rate</th>\n",
       "      <th>Dst_host_srv_serror_rate</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Label</th>\n",
       "      <th>Source_Port_Number</th>\n",
       "      <th>Destination_Port_Number</th>\n",
       "      <th>protocol_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S0</td>\n",
       "      <td>-1</td>\n",
       "      <td>47904</td>\n",
       "      <td>23</td>\n",
       "      <td>tcp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S0</td>\n",
       "      <td>-1</td>\n",
       "      <td>58974</td>\n",
       "      <td>23</td>\n",
       "      <td>tcp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S0</td>\n",
       "      <td>-1</td>\n",
       "      <td>37174</td>\n",
       "      <td>23</td>\n",
       "      <td>tcp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S0</td>\n",
       "      <td>-1</td>\n",
       "      <td>40711</td>\n",
       "      <td>3389</td>\n",
       "      <td>tcp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SH</td>\n",
       "      <td>-1</td>\n",
       "      <td>8429</td>\n",
       "      <td>22</td>\n",
       "      <td>tcp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration Service  Source_bytes  Destination_bytes  Count  Same_srv_rate  \\\n",
       "0  0.000000   other             0                  0      0            0.0   \n",
       "1  0.000000   other             0                  0      0            0.0   \n",
       "2  0.000000   other             0                  0      0            0.0   \n",
       "3  0.000000   other             0                  0      0            0.0   \n",
       "4  0.000052   other             0                  0      0            0.0   \n",
       "\n",
       "   Serror_rate  Srv_serror_rate  Dst_host_count  Dst_host_srv_count  \\\n",
       "0          0.0              0.0               0                   0   \n",
       "1          0.0              0.0               0                   0   \n",
       "2          0.0              0.0               0                   0   \n",
       "3          0.0              0.0               0                   0   \n",
       "4          0.0              0.0               0                   0   \n",
       "\n",
       "   Dst_host_same_src_port_rate  Dst_host_serror_rate  \\\n",
       "0                          0.0                   0.0   \n",
       "1                          0.0                   0.0   \n",
       "2                          0.0                   0.0   \n",
       "3                          0.0                   0.0   \n",
       "4                          0.0                   0.0   \n",
       "\n",
       "   Dst_host_srv_serror_rate Flag  Label  Source_Port_Number  \\\n",
       "0                       0.0   S0     -1               47904   \n",
       "1                       0.0   S0     -1               58974   \n",
       "2                       0.0   S0     -1               37174   \n",
       "3                       0.0   S0     -1               40711   \n",
       "4                       0.0   SH     -1                8429   \n",
       "\n",
       "   Destination_Port_Number protocol_type  \n",
       "0                       23           tcp  \n",
       "1                       23           tcp  \n",
       "2                       23           tcp  \n",
       "3                     3389           tcp  \n",
       "4                       22           tcp  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# for col in df.columns: \n",
    "#     print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def isNumber(s): \n",
    "\n",
    "#     # try to convert the string to int \n",
    "#     try: \n",
    "#         flag = s.isnumeric() \n",
    "#         return flag\n",
    "#     # catch exception if cannot be converted \n",
    "#     except AttributeError: \n",
    "#         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['Service' , 'Flag' , 'protocol_type']\n",
    "df = pd.get_dummies( df , columns = dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['IDS_detection'].replace( to_replace='0' , value = 0 )\n",
    "\n",
    "\n",
    "# for x in df['IDS_detection']: \n",
    "#     if ( x == 0 ):\n",
    "#         continue\n",
    "#     else:\n",
    "#         df['IDS_detection'].replace( to_replace=x , value = 1 )\n",
    "\n",
    "# df['IDS_detection'] = df['IDS_detection'].replace(to_replace=r\"^(.(?<!0))*?$\", value='Turf',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in df['Malware_detection']: \n",
    "#     if ( x != 0 or x != '0' ):\n",
    "#         df.at[x,'Malware_detection'] = 1\n",
    "\n",
    "# df['Malware_detection'].replace( to_replace='0' , value = 0 )\n",
    "\n",
    "\n",
    "# for x in df['Malware_detection']: \n",
    "#     if ( x == 0 ):\n",
    "#         continue\n",
    "#     else:\n",
    "#         df['Malware_detection'].replace( to_replace=x , value = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in df['Ashula_detection']: \n",
    "#     if ( x != 0 or x != '0' ):\n",
    "#         df.at[x,'Ashula_detection'] = 1\n",
    "\n",
    "# df['Ashula_detection'].replace( to_replace='0' , value = 0 )\n",
    "\n",
    "\n",
    "# for x in df['Ashula_detection']: \n",
    "#     if ( x == 0 ):\n",
    "#         continue\n",
    "#     else:\n",
    "#         df['Ashula_detection'].replace( to_replace=x , value = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Duration                       0\n",
       "Source_bytes                   0\n",
       "Destination_bytes              0\n",
       "Count                          0\n",
       "Same_srv_rate                  0\n",
       "Serror_rate                    0\n",
       "Srv_serror_rate                0\n",
       "Dst_host_count                 0\n",
       "Dst_host_srv_count             0\n",
       "Dst_host_same_src_port_rate    0\n",
       "Dst_host_serror_rate           0\n",
       "Dst_host_srv_serror_rate       0\n",
       "Label                          0\n",
       "Source_Port_Number             0\n",
       "Destination_Port_Number        0\n",
       "Service_dns                    0\n",
       "Service_http                   0\n",
       "Service_other                  0\n",
       "Service_rdp                    0\n",
       "Service_sip                    0\n",
       "Service_smtp                   0\n",
       "Service_smtp,ssl               0\n",
       "Service_snmp                   0\n",
       "Service_ssh                    0\n",
       "Flag_OTH                       0\n",
       "Flag_REJ                       0\n",
       "Flag_RSTO                      0\n",
       "Flag_RSTOS0                    0\n",
       "Flag_RSTR                      0\n",
       "Flag_RSTRH                     0\n",
       "Flag_S0                        0\n",
       "Flag_S1                        0\n",
       "Flag_SF                        0\n",
       "Flag_SH                        0\n",
       "Flag_SHR                       0\n",
       "protocol_type_icmp             0\n",
       "protocol_type_tcp              0\n",
       "protocol_type_udp              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Duration                       0\n",
       "Source_bytes                   0\n",
       "Destination_bytes              0\n",
       "Count                          0\n",
       "Same_srv_rate                  0\n",
       "Serror_rate                    0\n",
       "Srv_serror_rate                0\n",
       "Dst_host_count                 0\n",
       "Dst_host_srv_count             0\n",
       "Dst_host_same_src_port_rate    0\n",
       "Dst_host_serror_rate           0\n",
       "Dst_host_srv_serror_rate       0\n",
       "Label                          0\n",
       "Source_Port_Number             0\n",
       "Destination_Port_Number        0\n",
       "Service_dns                    0\n",
       "Service_http                   0\n",
       "Service_other                  0\n",
       "Service_rdp                    0\n",
       "Service_sip                    0\n",
       "Service_smtp                   0\n",
       "Service_smtp,ssl               0\n",
       "Service_snmp                   0\n",
       "Service_ssh                    0\n",
       "Flag_OTH                       0\n",
       "Flag_REJ                       0\n",
       "Flag_RSTO                      0\n",
       "Flag_RSTOS0                    0\n",
       "Flag_RSTR                      0\n",
       "Flag_RSTRH                     0\n",
       "Flag_S0                        0\n",
       "Flag_S1                        0\n",
       "Flag_SF                        0\n",
       "Flag_SH                        0\n",
       "Flag_SHR                       0\n",
       "protocol_type_icmp             0\n",
       "protocol_type_tcp              0\n",
       "protocol_type_udp              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Source_bytes</th>\n",
       "      <th>Destination_bytes</th>\n",
       "      <th>Count</th>\n",
       "      <th>Same_srv_rate</th>\n",
       "      <th>Serror_rate</th>\n",
       "      <th>Srv_serror_rate</th>\n",
       "      <th>Dst_host_count</th>\n",
       "      <th>Dst_host_srv_count</th>\n",
       "      <th>Dst_host_same_src_port_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Flag_RSTR</th>\n",
       "      <th>Flag_RSTRH</th>\n",
       "      <th>Flag_S0</th>\n",
       "      <th>Flag_S1</th>\n",
       "      <th>Flag_SF</th>\n",
       "      <th>Flag_SH</th>\n",
       "      <th>Flag_SHR</th>\n",
       "      <th>protocol_type_icmp</th>\n",
       "      <th>protocol_type_tcp</th>\n",
       "      <th>protocol_type_udp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329583</th>\n",
       "      <td>0.000454</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85372</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267953</th>\n",
       "      <td>0.000453</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375435</th>\n",
       "      <td>0.000516</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347629</th>\n",
       "      <td>1.604261</td>\n",
       "      <td>536</td>\n",
       "      <td>1745</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Duration  Source_bytes  Destination_bytes  Count  Same_srv_rate  \\\n",
       "329583  0.000454            44                104     15            1.0   \n",
       "85372   0.000000             0                  0      0            0.0   \n",
       "267953  0.000453            44                104     24            1.0   \n",
       "375435  0.000516            44                104     11            1.0   \n",
       "347629  1.604261           536               1745      1            1.0   \n",
       "\n",
       "        Serror_rate  Srv_serror_rate  Dst_host_count  Dst_host_srv_count  \\\n",
       "329583          0.0              0.0              89                  99   \n",
       "85372           0.0              1.0               2                   2   \n",
       "267953          0.0              0.0              92                  99   \n",
       "375435          0.0              0.0              84                  99   \n",
       "347629          0.0              0.0              24                  24   \n",
       "\n",
       "        Dst_host_same_src_port_rate        ...          Flag_RSTR  Flag_RSTRH  \\\n",
       "329583                          0.0        ...                  0           0   \n",
       "85372                           1.0        ...                  0           0   \n",
       "267953                          0.0        ...                  0           0   \n",
       "375435                          0.0        ...                  0           0   \n",
       "347629                          0.0        ...                  0           0   \n",
       "\n",
       "        Flag_S0  Flag_S1  Flag_SF  Flag_SH  Flag_SHR  protocol_type_icmp  \\\n",
       "329583        0        0        1        0         0                   0   \n",
       "85372         1        0        0        0         0                   0   \n",
       "267953        0        0        1        0         0                   0   \n",
       "375435        0        0        1        0         0                   0   \n",
       "347629        0        0        1        0         0                   0   \n",
       "\n",
       "        protocol_type_tcp  protocol_type_udp  \n",
       "329583                  0                  1  \n",
       "85372                   1                  0  \n",
       "267953                  0                  1  \n",
       "375435                  0                  1  \n",
       "347629                  1                  0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "# y = df.iloc[:, 38]\n",
    "# X = df.drop('label' , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score, average=\"micro\"),\n",
    "           'recall' : make_scorer(recall_score, average=\"micro\"), \n",
    "           'f1_score' : make_scorer(f1_score, average=\"micro\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Source_bytes</th>\n",
       "      <th>Destination_bytes</th>\n",
       "      <th>Count</th>\n",
       "      <th>Same_srv_rate</th>\n",
       "      <th>Serror_rate</th>\n",
       "      <th>Srv_serror_rate</th>\n",
       "      <th>Dst_host_count</th>\n",
       "      <th>Dst_host_srv_count</th>\n",
       "      <th>Dst_host_same_src_port_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Flag_RSTR</th>\n",
       "      <th>Flag_RSTRH</th>\n",
       "      <th>Flag_S0</th>\n",
       "      <th>Flag_S1</th>\n",
       "      <th>Flag_SF</th>\n",
       "      <th>Flag_SH</th>\n",
       "      <th>Flag_SHR</th>\n",
       "      <th>protocol_type_icmp</th>\n",
       "      <th>protocol_type_tcp</th>\n",
       "      <th>protocol_type_udp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329583</th>\n",
       "      <td>0.000454</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85372</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267953</th>\n",
       "      <td>0.000453</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375435</th>\n",
       "      <td>0.000516</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347629</th>\n",
       "      <td>1.604261</td>\n",
       "      <td>536</td>\n",
       "      <td>1745</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Duration  Source_bytes  Destination_bytes  Count  Same_srv_rate  \\\n",
       "329583  0.000454            44                104     15            1.0   \n",
       "85372   0.000000             0                  0      0            0.0   \n",
       "267953  0.000453            44                104     24            1.0   \n",
       "375435  0.000516            44                104     11            1.0   \n",
       "347629  1.604261           536               1745      1            1.0   \n",
       "\n",
       "        Serror_rate  Srv_serror_rate  Dst_host_count  Dst_host_srv_count  \\\n",
       "329583          0.0              0.0              89                  99   \n",
       "85372           0.0              1.0               2                   2   \n",
       "267953          0.0              0.0              92                  99   \n",
       "375435          0.0              0.0              84                  99   \n",
       "347629          0.0              0.0              24                  24   \n",
       "\n",
       "        Dst_host_same_src_port_rate        ...          Flag_RSTR  Flag_RSTRH  \\\n",
       "329583                          0.0        ...                  0           0   \n",
       "85372                           1.0        ...                  0           0   \n",
       "267953                          0.0        ...                  0           0   \n",
       "375435                          0.0        ...                  0           0   \n",
       "347629                          0.0        ...                  0           0   \n",
       "\n",
       "        Flag_S0  Flag_S1  Flag_SF  Flag_SH  Flag_SHR  protocol_type_icmp  \\\n",
       "329583        0        0        1        0         0                   0   \n",
       "85372         1        0        0        0         0                   0   \n",
       "267953        0        0        1        0         0                   0   \n",
       "375435        0        0        1        0         0                   0   \n",
       "347629        0        0        1        0         0                   0   \n",
       "\n",
       "        protocol_type_tcp  protocol_type_udp  \n",
       "329583                  0                  1  \n",
       "85372                   1                  0  \n",
       "267953                  0                  1  \n",
       "375435                  0                  1  \n",
       "347629                  1                  0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329583   -1\n",
       "85372    -1\n",
       "267953   -1\n",
       "375435   -1\n",
       "347629   -1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "#normalizing the data\n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "data_rescaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the PCA algorithm with our Data\n",
    "pca = PCA(n_components=5)\n",
    "principalComponents = pca.fit(data_rescaled)\n",
    "df_pca  = pca.fit_transform(data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(principalComponents.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('5 PC Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.76</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.47</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.76</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.52</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4\n",
       "0  1.76 -0.38 -0.07 -0.15  0.00\n",
       "1 -1.47 -0.38  0.51  0.29  0.67\n",
       "2  1.76 -0.42 -0.01 -0.23 -0.11\n",
       "3  1.75 -0.35 -0.12 -0.08  0.07\n",
       "4  0.52  1.41  0.27  0.16 -0.08"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store as dataframe and print\n",
    "df_pca = pd.DataFrame(df_pca )\n",
    "print(df_pca.shape)  #> (3147, 784)\n",
    "df_pca.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def encircle(x,y, ax=None, **kw):\n",
    "    if not ax: ax=plt.gca()\n",
    "    p = np.c_[x,y]\n",
    "    hull = ConvexHull(p)\n",
    "    poly = plt.Polygon(p[hull.vertices,:], **kw)\n",
    "    ax.add_patch(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No points given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-35136c0413a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Encircle the boundaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mencircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"blue\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"none\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mencircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"firebrick\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"none\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mencircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"green\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"none\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-133-0b28a74718f3>\u001b[0m in \u001b[0;36mencircle\u001b[1;34m(x, y, ax, **kw)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mhull\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvexHull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPolygon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhull\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_patch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull.ConvexHull.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull._Qhull.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No points given"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatterplot against PC1 and PC2\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,12))\n",
    "\n",
    "# Row masks for each category\n",
    "rows_0 = y==0;\n",
    "rows_1 = y==1; \n",
    "rows_2 = y==2; \n",
    "\n",
    "# Plot\n",
    "ax.scatter(df_pca.loc[rows_0.tolist(), 1], df_pca.loc[rows_0.tolist(), 2], c='blue', edgecolor='k', s=120, label='Zero')\n",
    "ax.scatter(df_pca.loc[rows_1.tolist(), 1], df_pca.loc[rows_1.tolist(), 2], c='red', edgecolor='k', s=120, label='One')\n",
    "ax.scatter(df_pca.loc[rows_2.tolist(), 1], df_pca.loc[rows_2.tolist(), 2], c='green', edgecolor='k', s=120, label='Two')\n",
    "\n",
    "# Encircle the boundaries\n",
    "encircle(df_pca.loc[rows_0.tolist(), 1], df_pca.loc[rows_0.tolist(), 2], ec=\"blue\", fc=\"none\", linewidth=2.5)\n",
    "encircle(df_pca.loc[rows_1.tolist(), 1], df_pca.loc[rows_1.tolist(), 2], ec=\"firebrick\", fc=\"none\", linewidth=2.5)\n",
    "encircle(df_pca.loc[rows_2.tolist(), 1], df_pca.loc[rows_2.tolist(), 2], ec=\"green\", fc=\"none\", linewidth=2.5)\n",
    "\n",
    "# Shading\n",
    "encircle(df_pca.loc[rows_1.tolist(), 1], df_pca.loc[rows_1.tolist(), 2], ec=\"k\", fc=\"firebrick\", alpha=0.05)\n",
    "encircle(df_pca.loc[rows_0.tolist(), 1], df_pca.loc[rows_0.tolist(), 2], ec=\"k\", fc=\"blue\", alpha=0.05)\n",
    "encircle(df_pca.loc[rows_2.tolist(), 1], df_pca.loc[rows_2.tolist(), 2], ec=\"k\", fc=\"green\", alpha=0.05)\n",
    "\n",
    "# Labels\n",
    "ax.set_title(\"MNIST Data for 1, 2 & 3: Scatterplot of First Two PCA directions\", fontsize=22)\n",
    "ax.set_xlabel(\"1st Principal Component\", fontsize=22)\n",
    "ax.set_ylabel(\"2nd Principal Component\", fontsize=22)\n",
    "ax.legend(loc='best', title='Transaction Type', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmModel = svm.SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  10 | elapsed:    4.8s remaining:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.9s remaining:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    5.0s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.1s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    5.1s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.1s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  10 | elapsed:    5.4s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "svmScore = cross_validate(svmModel, df_pca, y, cv=10, scoring=scoring_metrics, verbose=15 ,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "ss = pd.DataFrame(svmScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135920</td>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.942643</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.942643</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.942643</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.942643</td>\n",
       "      <td>0.944707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136429</td>\n",
       "      <td>0.042975</td>\n",
       "      <td>0.927681</td>\n",
       "      <td>0.945540</td>\n",
       "      <td>0.927681</td>\n",
       "      <td>0.945540</td>\n",
       "      <td>0.927681</td>\n",
       "      <td>0.945540</td>\n",
       "      <td>0.927681</td>\n",
       "      <td>0.945540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142918</td>\n",
       "      <td>0.045481</td>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.942484</td>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.942484</td>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.942484</td>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.942484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.137920</td>\n",
       "      <td>0.045973</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.942484</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.942484</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.942484</td>\n",
       "      <td>0.952618</td>\n",
       "      <td>0.942484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.151420</td>\n",
       "      <td>0.203884</td>\n",
       "      <td>0.945137</td>\n",
       "      <td>0.943595</td>\n",
       "      <td>0.945137</td>\n",
       "      <td>0.943595</td>\n",
       "      <td>0.945137</td>\n",
       "      <td>0.943595</td>\n",
       "      <td>0.945137</td>\n",
       "      <td>0.943595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy  test_precision  \\\n",
       "0  0.135920    0.046974       0.942643        0.944707        0.942643   \n",
       "1  0.136429    0.042975       0.927681        0.945540        0.927681   \n",
       "2  0.142918    0.045481       0.957606        0.942484        0.957606   \n",
       "3  0.137920    0.045973       0.952618        0.942484        0.952618   \n",
       "4  0.151420    0.203884       0.945137        0.943595        0.945137   \n",
       "\n",
       "   train_precision  test_recall  train_recall  test_f1_score  train_f1_score  \n",
       "0         0.944707     0.942643      0.944707       0.942643        0.944707  \n",
       "1         0.945540     0.927681      0.945540       0.927681        0.945540  \n",
       "2         0.942484     0.957606      0.942484       0.957606        0.942484  \n",
       "3         0.942484     0.952618      0.942484       0.952618        0.942484  \n",
       "4         0.943595     0.945137      0.943595       0.945137        0.943595  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9434958968493554"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('Kyoto_SVM_PCA5_Scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestModel = RandomForestClassifier(max_depth=2, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "randomForestScore = cross_validate(randomForestModel, df_pca, y, cv=3 , scoring=scoring_metrics, verbose=15 ,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "randomForestScore = pd.DataFrame(randomForestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestScore.to_csv('Kyoto_RandomForest_PCA5_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters={'n_estimators' : range(80,200,20),'max_depth': range(1,20,3), 'min_samples_split': np.arange(0.1,1,0.1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlGrid = GridSearchCV(rf2, rf_parameters, scoring=scoring_metrics, refit='accuracy', verbose=15, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 378 candidates, totalling 1134 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed:   12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 247 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 253 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 254 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 255 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 259 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done 262 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done 263 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 267 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 269 tasks      | elapsed:   27.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 270 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 271 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 273 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 274 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 275 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 277 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 279 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 282 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 283 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 286 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 287 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 291 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 293 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 294 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 295 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 298 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 299 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 301 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 302 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 303 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done 307 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 309 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 310 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 311 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 313 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 315 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 316 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 318 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 319 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 321 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 323 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 324 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 325 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 326 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 327 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 329 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 331 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 332 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 335 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done 336 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 337 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done 339 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done 340 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 342 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 343 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 345 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 346 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done 347 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 348 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 351 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 355 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 356 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 358 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 359 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 362 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 363 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 364 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 365 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=-1)]: Done 366 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=-1)]: Done 367 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 369 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 371 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 372 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=-1)]: Done 374 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=-1)]: Done 375 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 377 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 378 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done 379 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 380 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done 381 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 383 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done 385 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 387 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 390 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 391 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 392 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 393 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 394 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done 395 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 398 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done 399 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done 400 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 401 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done 403 tasks      | elapsed:   41.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 404 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=-1)]: Done 406 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 407 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 408 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=-1)]: Done 409 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done 410 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done 411 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done 412 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 414 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 415 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=-1)]: Done 416 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=-1)]: Done 417 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 419 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 420 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 421 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 422 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 423 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 425 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 427 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 431 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done 432 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 433 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 435 tasks      | elapsed:   44.1s\n",
      "[Parallel(n_jobs=-1)]: Done 436 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 439 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 441 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 443 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 444 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 445 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 447 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done 448 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done 450 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 451 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 452 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=-1)]: Done 453 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 454 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 458 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 459 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 460 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=-1)]: Done 462 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 463 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 464 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 467 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done 468 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 469 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 470 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 471 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 475 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 476 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 477 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=-1)]: Done 478 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 479 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 481 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 482 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 483 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 485 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 486 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 487 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 489 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 490 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done 491 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 493 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 494 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done 495 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 497 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 499 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 501 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 502 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 503 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 505 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 506 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 507 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=-1)]: Done 509 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=-1)]: Done 510 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done 511 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 512 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done 514 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=-1)]: Done 515 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=-1)]: Done 516 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done 517 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done 519 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 522 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 523 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 524 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 525 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done 526 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done 527 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done 531 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done 532 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 533 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 534 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 535 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:   55.5s\n",
      "[Parallel(n_jobs=-1)]: Done 538 tasks      | elapsed:   55.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 539 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=-1)]: Done 540 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 541 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 542 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 543 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=-1)]: Done 544 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 545 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=-1)]: Done 547 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done 548 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=-1)]: Done 549 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=-1)]: Done 550 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-1)]: Done 551 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 553 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 555 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 556 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 557 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 558 tasks      | elapsed:   58.0s\n",
      "[Parallel(n_jobs=-1)]: Done 559 tasks      | elapsed:   58.0s\n",
      "[Parallel(n_jobs=-1)]: Done 560 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=-1)]: Done 561 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done 563 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 565 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 566 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 567 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done 568 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done 569 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 571 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 572 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=-1)]: Done 573 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=-1)]: Done 574 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=-1)]: Done 575 tasks      | elapsed:   60.0s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 577 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 578 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 579 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 580 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 582 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 583 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 584 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 585 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 586 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 587 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 588 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 590 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 591 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 592 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 593 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 594 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 595 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 596 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 598 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 599 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 601 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 602 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 603 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 604 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 607 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 609 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 610 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 611 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 613 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 614 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 615 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 617 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 618 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 619 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 620 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 621 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 622 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 623 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 625 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 626 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 627 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 628 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 629 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 630 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 631 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 633 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 634 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 635 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 636 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 637 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 638 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 639 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 641 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 642 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 643 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 645 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 646 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 647 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 648 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 649 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 651 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 652 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 654 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 655 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 657 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 659 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 660 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 662 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 663 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 665 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 666 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 667 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 670 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 671 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 673 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 674 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 675 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 676 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 678 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 679 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 680 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 681 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 682 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 683 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 684 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 685 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 686 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 687 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 689 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 691 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 692 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 693 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 694 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 695 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 696 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 697 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 699 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 700 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 701 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 702 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 703 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 705 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 707 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 709 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 710 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 711 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 712 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 713 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 715 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 716 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 717 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 719 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 720 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 721 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 722 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 723 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 724 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 725 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 726 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 727 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 728 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 730 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 731 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 732 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 733 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 734 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 735 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 737 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 738 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 739 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 740 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 741 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 742 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 743 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 746 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 747 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 748 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 749 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 750 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 751 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 754 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 755 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 756 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 757 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 758 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 759 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 760 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 761 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 762 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 763 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 764 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 765 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 766 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 767 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 769 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 770 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 771 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 772 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 773 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 775 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 777 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 778 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 779 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 781 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 782 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 783 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 785 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 786 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 787 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 789 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 790 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 791 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 793 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 794 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 795 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 797 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 798 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 799 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 800 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 801 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 802 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 803 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 804 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 805 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 806 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 807 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 808 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 810 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 811 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 812 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 813 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 814 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 815 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 816 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 817 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 818 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 819 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 820 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 821 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 822 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 823 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 826 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 827 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 829 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 830 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 831 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 835 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 836 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 837 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 838 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 839 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 840 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 841 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 842 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 843 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 844 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 845 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 846 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 847 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 849 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 851 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 853 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 854 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 855 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 856 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 857 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 859 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 860 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 861 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 862 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 863 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 864 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 865 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 867 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 868 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 869 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 870 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 871 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 872 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 873 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 875 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 877 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 878 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 879 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 880 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 881 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 882 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 883 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 884 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 885 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 886 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 887 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 889 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 890 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 891 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 892 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 894 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 895 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 897 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 898 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 899 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 900 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 901 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 902 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 903 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 904 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 905 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 906 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 907 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 908 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 910 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 911 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 912 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 913 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 914 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 915 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 916 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 918 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 919 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 920 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 921 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 922 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 923 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 924 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 925 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 926 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 927 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 928 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 929 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 930 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 931 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 932 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 933 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 934 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 935 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 937 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 938 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 939 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 940 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 941 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 942 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 943 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 944 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 945 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 946 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 947 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 948 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 949 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 950 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 951 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 953 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 954 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 955 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 956 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 957 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 958 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 959 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 961 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 962 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 963 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 966 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 967 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 968 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 969 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 970 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 971 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 972 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 973 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 974 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 975 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 977 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 978 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 979 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 980 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 982 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 983 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 984 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 985 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 986 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 987 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 988 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 990 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 991 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 992 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 993 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 994 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 995 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 996 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 998 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 999 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1001 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1002 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1003 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1004 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1006 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1007 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1010 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1011 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1013 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1014 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1015 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1016 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1017 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1018 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1019 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1020 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1021 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1022 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1023 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1024 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1025 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1027 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1028 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1029 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1030 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1031 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1032 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1033 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1035 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1036 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1037 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1038 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1039 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1040 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1041 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1043 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1044 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1045 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1046 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1047 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1048 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1049 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1051 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1052 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1053 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1054 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1055 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1056 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1057 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1058 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1059 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1060 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1061 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1062 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1063 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1064 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1065 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1066 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1067 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1068 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1069 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1070 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1071 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1072 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1074 tasks      | elapsed:  1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1075 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1076 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1077 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1078 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1079 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1081 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1082 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1083 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1084 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1085 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1086 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1087 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1088 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1089 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1090 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1091 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1092 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1093 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1094 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1095 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1098 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1099 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1100 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1101 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1102 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1103 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1105 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1106 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1107 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1108 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1109 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1110 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1111 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1112 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1113 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1114 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1115 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1116 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1117 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1118 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1119 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1134 out of 1134 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': range(80, 200, 20), 'max_depth': range(1, 20, 3), 'min_samples_split': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "       pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=micro), 'recall': make_scorer(recall_score, average=micro), 'f1_score': make_scorer(f1_score, average=micro)},\n",
       "       verbose=15)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlGrid.fit(df_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_f1_score</th>\n",
       "      <th>split2_test_f1_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>std_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "      <th>split0_train_f1_score</th>\n",
       "      <th>split1_train_f1_score</th>\n",
       "      <th>split2_train_f1_score</th>\n",
       "      <th>mean_train_f1_score</th>\n",
       "      <th>std_train_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.214544</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.094612</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>38</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.267846</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>0.120597</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>38</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343803</td>\n",
       "      <td>0.065098</td>\n",
       "      <td>0.188891</td>\n",
       "      <td>0.068822</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>120</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>38</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.370121</td>\n",
       "      <td>0.028295</td>\n",
       "      <td>0.165572</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>140</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>38</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.447076</td>\n",
       "      <td>0.045010</td>\n",
       "      <td>0.198553</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>160</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>38</td>\n",
       "      <td>0.891223</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.214544      0.020794         0.094612        0.003856   \n",
       "1       0.267846      0.020204         0.120597        0.008571   \n",
       "2       0.343803      0.065098         0.188891        0.068822   \n",
       "3       0.370121      0.028295         0.165572        0.007538   \n",
       "4       0.447076      0.045010         0.198553        0.011079   \n",
       "\n",
       "  param_max_depth param_min_samples_split param_n_estimators  \\\n",
       "0               1                     0.1                 80   \n",
       "1               1                     0.1                100   \n",
       "2               1                     0.1                120   \n",
       "3               1                     0.1                140   \n",
       "4               1                     0.1                160   \n",
       "\n",
       "                                              params  split0_test_accuracy  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 0.1, 'n_...              0.891304   \n",
       "1  {'max_depth': 1, 'min_samples_split': 0.1, 'n_...              0.891304   \n",
       "2  {'max_depth': 1, 'min_samples_split': 0.1, 'n_...              0.891304   \n",
       "3  {'max_depth': 1, 'min_samples_split': 0.1, 'n_...              0.891304   \n",
       "4  {'max_depth': 1, 'min_samples_split': 0.1, 'n_...              0.891304   \n",
       "\n",
       "   split1_test_accuracy         ...          split1_test_f1_score  \\\n",
       "0              0.891223         ...                      0.891223   \n",
       "1              0.891223         ...                      0.891223   \n",
       "2              0.891223         ...                      0.891223   \n",
       "3              0.891223         ...                      0.891223   \n",
       "4              0.891223         ...                      0.891223   \n",
       "\n",
       "   split2_test_f1_score  mean_test_f1_score  std_test_f1_score  \\\n",
       "0              0.891223             0.89125           0.000038   \n",
       "1              0.891223             0.89125           0.000038   \n",
       "2              0.891223             0.89125           0.000038   \n",
       "3              0.891223             0.89125           0.000038   \n",
       "4              0.891223             0.89125           0.000038   \n",
       "\n",
       "   rank_test_f1_score  split0_train_f1_score  split1_train_f1_score  \\\n",
       "0                  38               0.891223               0.891264   \n",
       "1                  38               0.891223               0.891264   \n",
       "2                  38               0.891223               0.891264   \n",
       "3                  38               0.891223               0.891264   \n",
       "4                  38               0.891223               0.891264   \n",
       "\n",
       "   split2_train_f1_score  mean_train_f1_score  std_train_f1_score  \n",
       "0               0.891264              0.89125            0.000019  \n",
       "1               0.891264              0.89125            0.000019  \n",
       "2               0.891264              0.89125            0.000019  \n",
       "3               0.891264              0.89125            0.000019  \n",
       "4               0.891264              0.89125            0.000019  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtGridScores = pd.DataFrame(dlGrid.cv_results_)\n",
    "dtGridScores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGridScores.to_csv('Kyoto_RandomForest_PCA5_GridSearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt3=dlGrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 16, 'min_samples_split': 0.1, 'n_estimators': 100}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlGrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  10 | elapsed:    0.8s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.9s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    0.9s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    1.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    1.1s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  10 | elapsed:    1.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "dtFinalScore = cross_validate(dt3, df_pca, y, cv=10, scoring=scoring_metrics, verbose=15, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RandomForestFinalScore = pd.DataFrame(dtFinalScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestFinalScore.to_csv('Kyoto_RandomForest_PCA5_bestEstimator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpModel = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "mlpScore=cross_validate(mlpModel, df_pca , y, cv=4, scoring=scoring_metrics, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "mlpScore = pd.DataFrame(mlpScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpScore.to_csv(\"kyoto_MLP_PCA5_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "nLayers=[\n",
    "    (4),\n",
    "    (7),\n",
    "    (10), #one layer of 10 nodes\n",
    "    (13),\n",
    "    (17),\n",
    "    (20),\n",
    "    (30),\n",
    "    (50),\n",
    "    (80),\n",
    "    (100),\n",
    "    (120),\n",
    "    (140),\n",
    "    (180),\n",
    "    (220),\n",
    "    (10, 10), #two layers, 10 nodes each\n",
    "    (20, 20), #two layers, 20 nodes each\n",
    "    (30, 30),\n",
    "    (50, 50),\n",
    "    (80, 80),\n",
    "    (100, 100),\n",
    "    (150, 150),\n",
    "    (10, 10, 10), #three layers, 10 nodes each\n",
    "    (20, 20, 20),\n",
    "    (30, 30, 30),\n",
    "    (50, 50, 50),\n",
    "    (80, 80, 80),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_parameters = {\n",
    "    'hidden_layer_sizes': nLayers,\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.001, 0.01, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpModel2 = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_grid = GridSearchCV(mlpModel2, mlp_parameters, scoring=scoring_metrics, refit='accuracy', verbose=3, n_jobs=-1, cv=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 312 candidates, totalling 1248 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1248 out of 1248 | elapsed: 12.8min finished\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [4, 7, 10, 13, 17, 20, 30, 50, 80, 100, 120, 140, 180, 220, (10, 10), (20, 20), (30, 30), (50, 50), (80, 80), (100, 100), (150, 150), (10, 10, 10), (20, 20, 20), (30, 30, 30), (50, 50, 50), (80, 80, 80)], 'solver': ['sgd', 'adam'], 'alpha': [0.001, 0.01, 0.05], 'learning_rate': ['constant', 'adaptive']},\n",
       "       pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=micro), 'recall': make_scorer(recall_score, average=micro), 'f1_score': make_scorer(f1_score, average=micro)},\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_grid.fit(df_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "mlpGridScores=pd.DataFrame(mlp_grid.cv_results_)\n",
    "mlpGridScores.head()\n",
    "mlpGridScores.to_csv('Kyoto_MLP_PCA5_GridSearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01,\n",
       " 'hidden_layer_sizes': (30, 30, 30),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpFinalModel = mlp_grid.best_estimator_\n",
    "mlp_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.1s finished\n"
     ]
    }
   ],
   "source": [
    "mlpFinalScore=cross_validate(mlpFinalModel, df_pca, y, cv=4, scoring=scoring_metrics, verbose=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "mlpFinalScore = pd.DataFrame(mlpFinalScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpFinalScore.to_csv('Kyoto_MLP_PCA5_bestEstimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "dtScore = cross_validate(dt, df_pca, y, cv=4, scoring=scoring_metrics, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "dtScore = pd.DataFrame(dtScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtScore.to_csv('kyoto_DescisionTree_PCA5_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_parameters={'min_samples_split' : range(10,500,20),'max_depth': range(1,20,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlGrid = GridSearchCV(dt2, dt_parameters, scoring=scoring_metrics, refit='accuracy', verbose=3, n_jobs=-1, cv=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 250 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'min_samples_split': range(10, 500, 20), 'max_depth': range(1, 20, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=micro), 'recall': make_scorer(recall_score, average=micro), 'f1_score': make_scorer(f1_score, average=micro)},\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlGrid.fit(df_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_f1_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>std_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "      <th>split0_train_f1_score</th>\n",
       "      <th>split1_train_f1_score</th>\n",
       "      <th>split2_train_f1_score</th>\n",
       "      <th>split3_train_f1_score</th>\n",
       "      <th>mean_train_f1_score</th>\n",
       "      <th>std_train_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004747</td>\n",
       "      <td>1.478409e-03</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 10}</td>\n",
       "      <td>0.891109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>226</td>\n",
       "      <td>0.891297</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891036</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>6.529362e-07</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 30}</td>\n",
       "      <td>0.891109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>226</td>\n",
       "      <td>0.891297</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891036</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005757</td>\n",
       "      <td>2.413942e-04</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 50}</td>\n",
       "      <td>0.891109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>226</td>\n",
       "      <td>0.891297</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891036</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>4.321558e-04</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 70}</td>\n",
       "      <td>0.891109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>226</td>\n",
       "      <td>0.891297</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891036</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004998</td>\n",
       "      <td>7.067185e-04</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 90}</td>\n",
       "      <td>0.891109</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>226</td>\n",
       "      <td>0.891297</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891333</td>\n",
       "      <td>0.891036</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.004747  1.478409e-03         0.006747        0.001089   \n",
       "1       0.005996  6.529362e-07         0.007746        0.000433   \n",
       "2       0.005757  2.413942e-04         0.008240        0.000435   \n",
       "3       0.005747  4.321558e-04         0.008245        0.000433   \n",
       "4       0.004998  7.067185e-04         0.006496        0.001118   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "0               1                      10   \n",
       "1               1                      30   \n",
       "2               1                      50   \n",
       "3               1                      70   \n",
       "4               1                      90   \n",
       "\n",
       "                                      params  split0_test_accuracy  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 10}              0.891109   \n",
       "1  {'max_depth': 1, 'min_samples_split': 30}              0.891109   \n",
       "2  {'max_depth': 1, 'min_samples_split': 50}              0.891109   \n",
       "3  {'max_depth': 1, 'min_samples_split': 70}              0.891109   \n",
       "4  {'max_depth': 1, 'min_samples_split': 90}              0.891109   \n",
       "\n",
       "   split1_test_accuracy  split2_test_accuracy         ...          \\\n",
       "0                 0.891                 0.891         ...           \n",
       "1                 0.891                 0.891         ...           \n",
       "2                 0.891                 0.891         ...           \n",
       "3                 0.891                 0.891         ...           \n",
       "4                 0.891                 0.891         ...           \n",
       "\n",
       "   split3_test_f1_score  mean_test_f1_score  std_test_f1_score  \\\n",
       "0              0.891892             0.89125           0.000373   \n",
       "1              0.891892             0.89125           0.000373   \n",
       "2              0.891892             0.89125           0.000373   \n",
       "3              0.891892             0.89125           0.000373   \n",
       "4              0.891892             0.89125           0.000373   \n",
       "\n",
       "   rank_test_f1_score  split0_train_f1_score  split1_train_f1_score  \\\n",
       "0                 226               0.891297               0.891333   \n",
       "1                 226               0.891297               0.891333   \n",
       "2                 226               0.891297               0.891333   \n",
       "3                 226               0.891297               0.891333   \n",
       "4                 226               0.891297               0.891333   \n",
       "\n",
       "   split2_train_f1_score  split3_train_f1_score  mean_train_f1_score  \\\n",
       "0               0.891333               0.891036              0.89125   \n",
       "1               0.891333               0.891036              0.89125   \n",
       "2               0.891333               0.891036              0.89125   \n",
       "3               0.891333               0.891036              0.89125   \n",
       "4               0.891333               0.891036              0.89125   \n",
       "\n",
       "   std_train_f1_score  \n",
       "0            0.000124  \n",
       "1            0.000124  \n",
       "2            0.000124  \n",
       "3            0.000124  \n",
       "4            0.000124  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtGridScores = pd.DataFrame(dlGrid.cv_results_)\n",
    "dtGridScores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGridScores.to_csv('Kyoto_DesicionTree_PCA5_GridSearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt3=dlGrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "dtFinalScore = cross_validate(dt3, df_pca, y, cv=4, scoring=scoring_metrics, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009979</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.949051</td>\n",
       "      <td>0.953318</td>\n",
       "      <td>0.949051</td>\n",
       "      <td>0.953318</td>\n",
       "      <td>0.949051</td>\n",
       "      <td>0.953318</td>\n",
       "      <td>0.949051</td>\n",
       "      <td>0.953318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.951333</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.951333</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.951333</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.951333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010008</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.956681</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.956681</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.956681</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.956681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy  test_precision  \\\n",
       "0  0.009979    0.006012       0.949051        0.953318        0.949051   \n",
       "1  0.009980    0.007010       0.948000        0.951333        0.948000   \n",
       "2  0.010008    0.004997       0.945000        0.952000        0.945000   \n",
       "3  0.013006    0.007981       0.936937        0.956681        0.936937   \n",
       "\n",
       "   train_precision  test_recall  train_recall  test_f1_score  train_f1_score  \n",
       "0         0.953318     0.949051      0.953318       0.949051        0.953318  \n",
       "1         0.951333     0.948000      0.951333       0.948000        0.951333  \n",
       "2         0.952000     0.945000      0.952000       0.945000        0.952000  \n",
       "3         0.956681     0.936937      0.956681       0.936937        0.956681  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtFinalScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447469714969714"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtFinalScore = pd.DataFrame(dtFinalScore)\n",
    "dtFinalScore['test_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtFinalScore.to_csv('Kyoto_DesicionTree_PCA5_bestEstimator.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 101, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = dict(n_neighbors=k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_dict, cv=4, scoring=scoring_metrics, refit='accuracy', verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96]},\n",
       "       pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=micro), 'recall': make_scorer(recall_score, average=micro), 'f1_score': make_scorer(f1_score, average=micro)},\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(df_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_f1_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>std_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "      <th>split0_train_f1_score</th>\n",
       "      <th>split1_train_f1_score</th>\n",
       "      <th>split2_train_f1_score</th>\n",
       "      <th>split3_train_f1_score</th>\n",
       "      <th>mean_train_f1_score</th>\n",
       "      <th>std_train_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104186</td>\n",
       "      <td>2.580008e-03</td>\n",
       "      <td>0.373766</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.952048</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>0.95025</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094192</td>\n",
       "      <td>3.261680e-03</td>\n",
       "      <td>0.420117</td>\n",
       "      <td>0.040886</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.943057</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.94625</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>5</td>\n",
       "      <td>0.955652</td>\n",
       "      <td>0.952333</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.959014</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005997</td>\n",
       "      <td>1.731581e-03</td>\n",
       "      <td>0.294580</td>\n",
       "      <td>0.020861</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.946054</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>0.94700</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950650</td>\n",
       "      <td>0.948667</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.952016</td>\n",
       "      <td>0.950583</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006247</td>\n",
       "      <td>2.163771e-03</td>\n",
       "      <td>0.307573</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.94700</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>2</td>\n",
       "      <td>0.947983</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.949683</td>\n",
       "      <td>0.948250</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004747</td>\n",
       "      <td>4.330846e-04</td>\n",
       "      <td>0.299829</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>0.94625</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>5</td>\n",
       "      <td>0.946982</td>\n",
       "      <td>0.945667</td>\n",
       "      <td>0.946333</td>\n",
       "      <td>0.947351</td>\n",
       "      <td>0.946583</td>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005247</td>\n",
       "      <td>4.327405e-04</td>\n",
       "      <td>0.309822</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>26</td>\n",
       "      <td>{'n_neighbors': 26}</td>\n",
       "      <td>0.943057</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.943944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.94625</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>5</td>\n",
       "      <td>0.947649</td>\n",
       "      <td>0.946333</td>\n",
       "      <td>0.945667</td>\n",
       "      <td>0.947684</td>\n",
       "      <td>0.946833</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005247</td>\n",
       "      <td>4.327406e-04</td>\n",
       "      <td>0.337338</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>31</td>\n",
       "      <td>{'n_neighbors': 31}</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.94650</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>4</td>\n",
       "      <td>0.946982</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>0.946351</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.000846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004997</td>\n",
       "      <td>3.526258e-07</td>\n",
       "      <td>0.334314</td>\n",
       "      <td>0.017426</td>\n",
       "      <td>36</td>\n",
       "      <td>{'n_neighbors': 36}</td>\n",
       "      <td>0.946054</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.944945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944945</td>\n",
       "      <td>0.94575</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>8</td>\n",
       "      <td>0.946315</td>\n",
       "      <td>0.946333</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.946018</td>\n",
       "      <td>0.945917</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005496</td>\n",
       "      <td>1.500090e-03</td>\n",
       "      <td>0.357794</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>41</td>\n",
       "      <td>{'n_neighbors': 41}</td>\n",
       "      <td>0.946054</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>0.94500</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>9</td>\n",
       "      <td>0.944315</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.944333</td>\n",
       "      <td>0.945352</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005247</td>\n",
       "      <td>4.327753e-04</td>\n",
       "      <td>0.373785</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>46</td>\n",
       "      <td>{'n_neighbors': 46}</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>0.94225</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>10</td>\n",
       "      <td>0.944982</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.944333</td>\n",
       "      <td>0.945685</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>0.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004747</td>\n",
       "      <td>4.326375e-04</td>\n",
       "      <td>0.352681</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>51</td>\n",
       "      <td>{'n_neighbors': 51}</td>\n",
       "      <td>0.936064</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.935936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935936</td>\n",
       "      <td>0.93650</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>17</td>\n",
       "      <td>0.937979</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.937354</td>\n",
       "      <td>0.937167</td>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005246</td>\n",
       "      <td>4.330508e-04</td>\n",
       "      <td>0.441247</td>\n",
       "      <td>0.069812</td>\n",
       "      <td>56</td>\n",
       "      <td>{'n_neighbors': 56}</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.93725</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>15</td>\n",
       "      <td>0.936646</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.936688</td>\n",
       "      <td>0.936583</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004624</td>\n",
       "      <td>4.136122e-04</td>\n",
       "      <td>0.417090</td>\n",
       "      <td>0.060231</td>\n",
       "      <td>61</td>\n",
       "      <td>{'n_neighbors': 61}</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.93625</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>18</td>\n",
       "      <td>0.934311</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.936688</td>\n",
       "      <td>0.935916</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004747</td>\n",
       "      <td>4.327405e-04</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.026664</td>\n",
       "      <td>66</td>\n",
       "      <td>{'n_neighbors': 66}</td>\n",
       "      <td>0.933067</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>0.93625</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>18</td>\n",
       "      <td>0.934978</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.940667</td>\n",
       "      <td>0.937021</td>\n",
       "      <td>0.937166</td>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>8.293838e-04</td>\n",
       "      <td>0.409271</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>71</td>\n",
       "      <td>{'n_neighbors': 71}</td>\n",
       "      <td>0.933067</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>0.93625</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>18</td>\n",
       "      <td>0.934978</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.936688</td>\n",
       "      <td>0.937667</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>9.995103e-04</td>\n",
       "      <td>0.407516</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>76</td>\n",
       "      <td>{'n_neighbors': 76}</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.934935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934935</td>\n",
       "      <td>0.93725</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>15</td>\n",
       "      <td>0.934978</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>0.937354</td>\n",
       "      <td>0.938083</td>\n",
       "      <td>0.002980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004997</td>\n",
       "      <td>7.063816e-04</td>\n",
       "      <td>0.507369</td>\n",
       "      <td>0.066756</td>\n",
       "      <td>81</td>\n",
       "      <td>{'n_neighbors': 81}</td>\n",
       "      <td>0.943057</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>0.93925</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>14</td>\n",
       "      <td>0.943314</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.942667</td>\n",
       "      <td>0.937354</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004885</td>\n",
       "      <td>5.384395e-04</td>\n",
       "      <td>0.409842</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>86</td>\n",
       "      <td>{'n_neighbors': 86}</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.937938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937938</td>\n",
       "      <td>0.94225</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>10</td>\n",
       "      <td>0.942981</td>\n",
       "      <td>0.942333</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.937354</td>\n",
       "      <td>0.941084</td>\n",
       "      <td>0.002203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004747</td>\n",
       "      <td>8.283234e-04</td>\n",
       "      <td>0.482871</td>\n",
       "      <td>0.089010</td>\n",
       "      <td>91</td>\n",
       "      <td>{'n_neighbors': 91}</td>\n",
       "      <td>0.943057</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.939940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939940</td>\n",
       "      <td>0.94150</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>12</td>\n",
       "      <td>0.940980</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.944352</td>\n",
       "      <td>0.942083</td>\n",
       "      <td>0.001855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.004997</td>\n",
       "      <td>3.908538e-07</td>\n",
       "      <td>0.567858</td>\n",
       "      <td>0.094928</td>\n",
       "      <td>96</td>\n",
       "      <td>{'n_neighbors': 96}</td>\n",
       "      <td>0.941059</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.938939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938939</td>\n",
       "      <td>0.93975</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>13</td>\n",
       "      <td>0.939980</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.944352</td>\n",
       "      <td>0.941416</td>\n",
       "      <td>0.002551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.104186  2.580008e-03         0.373766        0.006755   \n",
       "1        0.094192  3.261680e-03         0.420117        0.040886   \n",
       "2        0.005997  1.731581e-03         0.294580        0.020861   \n",
       "3        0.006247  2.163771e-03         0.307573        0.021217   \n",
       "4        0.004747  4.330846e-04         0.299829        0.006591   \n",
       "5        0.005247  4.327405e-04         0.309822        0.011084   \n",
       "6        0.005247  4.327406e-04         0.337338        0.014363   \n",
       "7        0.004997  3.526258e-07         0.334314        0.017426   \n",
       "8        0.005496  1.500090e-03         0.357794        0.037074   \n",
       "9        0.005247  4.327753e-04         0.373785        0.054499   \n",
       "10       0.004747  4.326375e-04         0.352681        0.010165   \n",
       "11       0.005246  4.330508e-04         0.441247        0.069812   \n",
       "12       0.004624  4.136122e-04         0.417090        0.060231   \n",
       "13       0.004747  4.327405e-04         0.375940        0.026664   \n",
       "14       0.005747  8.293838e-04         0.409271        0.018122   \n",
       "15       0.005996  9.995103e-04         0.407516        0.020992   \n",
       "16       0.004997  7.063816e-04         0.507369        0.066756   \n",
       "17       0.004885  5.384395e-04         0.409842        0.023844   \n",
       "18       0.004747  8.283234e-04         0.482871        0.089010   \n",
       "19       0.004997  3.908538e-07         0.567858        0.094928   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_accuracy  \\\n",
       "0                  1   {'n_neighbors': 1}              0.952048   \n",
       "1                  6   {'n_neighbors': 6}              0.943057   \n",
       "2                 11  {'n_neighbors': 11}              0.946054   \n",
       "3                 16  {'n_neighbors': 16}              0.944056   \n",
       "4                 21  {'n_neighbors': 21}              0.945055   \n",
       "5                 26  {'n_neighbors': 26}              0.943057   \n",
       "6                 31  {'n_neighbors': 31}              0.944056   \n",
       "7                 36  {'n_neighbors': 36}              0.946054   \n",
       "8                 41  {'n_neighbors': 41}              0.946054   \n",
       "9                 46  {'n_neighbors': 46}              0.944056   \n",
       "10                51  {'n_neighbors': 51}              0.936064   \n",
       "11                56  {'n_neighbors': 56}              0.937063   \n",
       "12                61  {'n_neighbors': 61}              0.934066   \n",
       "13                66  {'n_neighbors': 66}              0.933067   \n",
       "14                71  {'n_neighbors': 71}              0.933067   \n",
       "15                76  {'n_neighbors': 76}              0.935065   \n",
       "16                81  {'n_neighbors': 81}              0.943057   \n",
       "17                86  {'n_neighbors': 86}              0.944056   \n",
       "18                91  {'n_neighbors': 91}              0.943057   \n",
       "19                96  {'n_neighbors': 96}              0.941059   \n",
       "\n",
       "    split1_test_accuracy  split2_test_accuracy  split3_test_accuracy  \\\n",
       "0                  0.949                 0.957              0.942943   \n",
       "1                  0.948                 0.948              0.945946   \n",
       "2                  0.951                 0.948              0.942943   \n",
       "3                  0.950                 0.948              0.945946   \n",
       "4                  0.950                 0.947              0.942943   \n",
       "5                  0.949                 0.949              0.943944   \n",
       "6                  0.949                 0.947              0.945946   \n",
       "7                  0.945                 0.947              0.944945   \n",
       "8                  0.945                 0.946              0.942943   \n",
       "9                  0.936                 0.946              0.942943   \n",
       "10                 0.936                 0.938              0.935936   \n",
       "11                 0.936                 0.939              0.936937   \n",
       "12                 0.935                 0.939              0.936937   \n",
       "13                 0.933                 0.945              0.933934   \n",
       "14                 0.932                 0.946              0.933934   \n",
       "15                 0.932                 0.947              0.934935   \n",
       "16                 0.933                 0.947              0.933934   \n",
       "17                 0.941                 0.946              0.937938   \n",
       "18                 0.942                 0.941              0.939940   \n",
       "19                 0.941                 0.938              0.938939   \n",
       "\n",
       "           ...          split3_test_f1_score  mean_test_f1_score  \\\n",
       "0          ...                      0.942943             0.95025   \n",
       "1          ...                      0.945946             0.94625   \n",
       "2          ...                      0.942943             0.94700   \n",
       "3          ...                      0.945946             0.94700   \n",
       "4          ...                      0.942943             0.94625   \n",
       "5          ...                      0.943944             0.94625   \n",
       "6          ...                      0.945946             0.94650   \n",
       "7          ...                      0.944945             0.94575   \n",
       "8          ...                      0.942943             0.94500   \n",
       "9          ...                      0.942943             0.94225   \n",
       "10         ...                      0.935936             0.93650   \n",
       "11         ...                      0.936937             0.93725   \n",
       "12         ...                      0.936937             0.93625   \n",
       "13         ...                      0.933934             0.93625   \n",
       "14         ...                      0.933934             0.93625   \n",
       "15         ...                      0.934935             0.93725   \n",
       "16         ...                      0.933934             0.93925   \n",
       "17         ...                      0.937938             0.94225   \n",
       "18         ...                      0.939940             0.94150   \n",
       "19         ...                      0.938939             0.93975   \n",
       "\n",
       "    std_test_f1_score  rank_test_f1_score  split0_train_f1_score  \\\n",
       "0            0.005092                   1               1.000000   \n",
       "1            0.002026                   5               0.955652   \n",
       "2            0.002930                   2               0.950650   \n",
       "3            0.002224                   2               0.947983   \n",
       "4            0.002597                   5               0.946982   \n",
       "5            0.002768                   5               0.947649   \n",
       "6            0.001788                   4               0.946982   \n",
       "7            0.000846                   8               0.946315   \n",
       "8            0.001259                   9               0.944315   \n",
       "9            0.003771                  10               0.944982   \n",
       "10           0.000867                  17               0.937979   \n",
       "11           0.001091                  15               0.936646   \n",
       "12           0.001895                  18               0.934311   \n",
       "13           0.005065                  18               0.934978   \n",
       "14           0.005671                  18               0.934978   \n",
       "15           0.005761                  15               0.934978   \n",
       "16           0.005955                  14               0.943314   \n",
       "17           0.003060                  10               0.942981   \n",
       "18           0.001157                  12               0.940980   \n",
       "19           0.001323                  13               0.939980   \n",
       "\n",
       "    split1_train_f1_score  split2_train_f1_score  split3_train_f1_score  \\\n",
       "0                1.000000               1.000000               1.000000   \n",
       "1                0.952333               0.957000               0.959014   \n",
       "2                0.948667               0.951000               0.952016   \n",
       "3                0.948000               0.947333               0.949683   \n",
       "4                0.945667               0.946333               0.947351   \n",
       "5                0.946333               0.945667               0.947684   \n",
       "6                0.946000               0.944667               0.946351   \n",
       "7                0.946333               0.945000               0.946018   \n",
       "8                0.946000               0.944333               0.945352   \n",
       "9                0.937000               0.944333               0.945685   \n",
       "10               0.937333               0.936000               0.937354   \n",
       "11               0.937000               0.936000               0.936688   \n",
       "12               0.936667               0.936000               0.936688   \n",
       "13               0.936000               0.940667               0.937021   \n",
       "14               0.937000               0.942000               0.936688   \n",
       "15               0.937000               0.943000               0.937354   \n",
       "16               0.937000               0.942667               0.937354   \n",
       "17               0.942333               0.941667               0.937354   \n",
       "18               0.943333               0.939667               0.944352   \n",
       "19               0.943333               0.938000               0.944352   \n",
       "\n",
       "    mean_train_f1_score  std_train_f1_score  \n",
       "0              1.000000            0.000000  \n",
       "1              0.956000            0.002431  \n",
       "2              0.950583            0.001215  \n",
       "3              0.948250            0.000870  \n",
       "4              0.946583            0.000642  \n",
       "5              0.946833            0.000866  \n",
       "6              0.946000            0.000846  \n",
       "7              0.945917            0.000544  \n",
       "8              0.945000            0.000714  \n",
       "9              0.943000            0.003497  \n",
       "10             0.937167            0.000722  \n",
       "11             0.936583            0.000364  \n",
       "12             0.935916            0.000967  \n",
       "13             0.937166            0.002146  \n",
       "14             0.937667            0.002618  \n",
       "15             0.938083            0.002980  \n",
       "16             0.940084            0.002918  \n",
       "17             0.941084            0.002203  \n",
       "18             0.942083            0.001855  \n",
       "19             0.941416            0.002551  \n",
       "\n",
       "[20 rows x 58 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnScore = pd.DataFrame(grid.cv_results_)\n",
    "knnScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2=grid.best_estimator_\n",
    "knn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "knnFinalScore = cross_validate(knn2, df_pca, y, cv=4, scoring=scoring_metrics, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "knnFinalScore = pd.DataFrame(knnFinalScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnFinalScore.to_csv('Kyoto_KNN_PCA5_bestEstimator.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.142372</td>\n",
       "      <td>3.463258</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.619984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.060667</td>\n",
       "      <td>0.014991</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.247108</td>\n",
       "      <td>0.098480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.944001</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>0.950248</td>\n",
       "      <td>0.945753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.944001</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>0.950248</td>\n",
       "      <td>0.945753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.944001</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>0.950248</td>\n",
       "      <td>0.945753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_score</th>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.944001</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>0.950248</td>\n",
       "      <td>0.945753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1_score</th>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4\n",
       "fit_time         0.142372  3.463258  0.010743  0.003998  0.619984\n",
       "score_time       0.060667  0.014991  0.006500  0.247108  0.098480\n",
       "test_accuracy    0.943496  0.944001  0.944747  0.950248  0.945753\n",
       "train_accuracy   0.943944  0.946667  0.953333  1.000000  0.947361\n",
       "test_precision   0.943496  0.944001  0.944747  0.950248  0.945753\n",
       "train_precision  0.943944  0.946667  0.953333  1.000000  0.947361\n",
       "test_recall      0.943496  0.944001  0.944747  0.950248  0.945753\n",
       "train_recall     0.943944  0.946667  0.953333  1.000000  0.947361\n",
       "test_f1_score    0.943496  0.944001  0.944747  0.950248  0.945753\n",
       "train_f1_score   0.943944  0.946667  0.953333  1.000000  0.947361"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allResults=pd.concat([\n",
    "    ss.mean(),\n",
    "    mlpScore.mean(),\n",
    "    dtFinalScore.mean(),\n",
    "    knnFinalScore.mean(),\n",
    "    RandomForestFinalScore.mean()], axis=1)\n",
    "allResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Multi-level Perceptron</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.142372</td>\n",
       "      <td>3.463258</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.619984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.060667</td>\n",
       "      <td>0.014991</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.247108</td>\n",
       "      <td>0.098480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.944001</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>0.950248</td>\n",
       "      <td>0.945753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.944001</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>0.950248</td>\n",
       "      <td>0.945753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.944001</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>0.950248</td>\n",
       "      <td>0.945753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_score</th>\n",
       "      <td>0.943496</td>\n",
       "      <td>0.944001</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>0.950248</td>\n",
       "      <td>0.945753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1_score</th>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      SVM  Multi-level Perceptron  Decision Tree       KNN  \\\n",
       "fit_time         0.142372                3.463258       0.010743  0.003998   \n",
       "score_time       0.060667                0.014991       0.006500  0.247108   \n",
       "test_accuracy    0.943496                0.944001       0.944747  0.950248   \n",
       "train_accuracy   0.943944                0.946667       0.953333  1.000000   \n",
       "test_precision   0.943496                0.944001       0.944747  0.950248   \n",
       "train_precision  0.943944                0.946667       0.953333  1.000000   \n",
       "test_recall      0.943496                0.944001       0.944747  0.950248   \n",
       "train_recall     0.943944                0.946667       0.953333  1.000000   \n",
       "test_f1_score    0.943496                0.944001       0.944747  0.950248   \n",
       "train_f1_score   0.943944                0.946667       0.953333  1.000000   \n",
       "\n",
       "                 Random Forest  \n",
       "fit_time              0.619984  \n",
       "score_time            0.098480  \n",
       "test_accuracy         0.945753  \n",
       "train_accuracy        0.947361  \n",
       "test_precision        0.945753  \n",
       "train_precision       0.947361  \n",
       "test_recall           0.945753  \n",
       "train_recall          0.947361  \n",
       "test_f1_score         0.945753  \n",
       "train_f1_score        0.947361  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allResults.rename(columns={0:'SVM', 1:'Multi-level Perceptron', 2:'Decision Tree', 3:'KNN' , 4:'Random Forest'},  inplace=True)\n",
    "allResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 5 and input n_features is 37 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-34ee86b567b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \"\"\"\n\u001b[0;32m    415\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tree_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    386\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 5 and input n_features is 37 "
     ]
    }
   ],
   "source": [
    "pred = dt3.predict(X)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
